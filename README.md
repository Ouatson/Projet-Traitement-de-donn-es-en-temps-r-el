# ğŸš€ Pipeline Data Streaming : Ingestion Clients (Kafka & Spark)

Ce projet implÃ©mente un pipeline de donnÃ©es **Temps RÃ©el** (Real-Time) robuste sur un environnement Big Data (HDP Sandbox). Il simule l'arrivÃ©e continue de nouveaux clients, les ingÃ¨re via Kafka, les traite avec Spark Structured Streaming, et les stocke sur HDFS selon leur validitÃ©.

## ğŸ“‹ Architecture du Pipeline

Le flux de donnÃ©es traverse les composants suivants :

1.  **Source** : Fichier CSV (\`customers.csv\`) simulant une base de donnÃ©es source.
2.  **Ingestion (Producer)** : Script Python (\`kafka_producer.py\`) qui publie les enregistrements en JSON dans **Kafka**.
3.  **Traitement (Spark Engine)** : Job Spark Streaming (\`spark_streaming_job.py\`) qui :
    * Lit le flux Kafka en continu (\`readStream\`).
    * Parse la structure JSON et nettoie les types de donnÃ©es.
    * Filtre les donnÃ©es : sÃ©pare les clients "USA" valides des donnÃ©es incomplÃ¨tes ("Alerts").
4.  **Stockage (HDFS)** :
    * \`/user/maria_dev/customers_usa_v2\` : DonnÃ©es propres (Parquet/JSON).
    * \`/user/maria_dev/customers_alerts_v2\` : Rejets et erreurs pour analyse.

---

## ğŸ“‚ Structure du Projet

Voici l'organisation recommandÃ©e des fichiers pour ce projet :

customer-streaming-pipeline/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ customers.csv            # DonnÃ©es sources (Ã©chantillon)
â”‚
â”œâ”€â”€ jars/
â”‚   â”œâ”€â”€ kafka-clients-1.1.1.jar
â”‚   â””â”€â”€ spark-sql-kafka-0-10_2.11-2.3.2.jar
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ kafka_producer.py        # Le Producer (envoie les donnÃ©es Ã  Kafka)
â”‚   â””â”€â”€ spark_streaming_job.py   # Le Job Spark (traitement temps rÃ©el)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ create_topic.sh          # Commande pour crÃ©er le topic Kafka
â”‚   â””â”€â”€ clean_env.sh             # Script de nettoyage HDFS/Checkpoints (utile en dev)
â”‚
â”œâ”€â”€ requirements.txt             # DÃ©pendances Python (kafka-python, etc.)
â”œâ”€â”€ .gitignore                   # Ignorer les fichiers temporaires (.pyc, tmp, .idea)
â””â”€â”€ README.md                    # Ce fichier

---

## ğŸ› ï¸ PrÃ©-requis

* **Environnement** : Hortonworks Data Platform (HDP Sandbox) ou Cluster Spark/Kafka.
* **Spark** : Version 2.3+ (Compatible Structured Streaming).
* **Kafka** : Topic configurÃ©.
* **Python** : 2.7 ou 3.6+.

---

## ğŸš€ Installation et DÃ©marrage

### 1. Configuration de Kafka
CrÃ©ation du topic qui recevra les donnÃ©es brutes :

\`\`\`bash
/usr/hdp/current/kafka-broker/bin/kafka-topics.sh \\
  --create \\
  --zookeeper sandbox-hdp.hortonworks.com:2181 \\
  --replication-factor 1 \\
  --partitions 1 \\
  --topic customers-raw
\`\`\`

### 2. DÃ©marrage du Producer
Ce script va lire le fichier CSV et envoyer les messages un par un dans Kafka.

\`\`\`bash
python kafka_producer.py
\`\`\`
*Laissez ce terminal ouvert ou lancez-le en arriÃ¨re-plan.*

### 3. ExÃ©cution du Job Spark
Soumettez le job Ã  YARN ou en local via \`spark-submit\`. Notez l'utilisation des \`.jars\` pour le connecteur Kafka.

\`\`\`bash
spark-submit \\
  --jars spark-sql-kafka-0-10_2.11-2.3.2.jar,kafka-clients-1.1.1.jar \\
  python_spark_job.py
\`\`\`

---

## âš™ï¸ Configuration Technique & Robustesse

Ce projet a Ã©tÃ© configurÃ© pour gÃ©rer les erreurs courantes en production :

### 1. Gestion des Pertes de DonnÃ©es (Data Loss)
Kafka peut supprimer des anciens messages (rÃ©tention) avant que Spark ne les lise. Pour Ã©viter que le job ne crash avec une erreur \`OffsetOutOfRangeException\`, nous utilisons :
\`\`\`python
.option("failOnDataLoss", "false")
\`\`\`

### 2. Checkpointing (TolÃ©rance aux pannes)
Spark utilise des dossiers de checkpoints locaux pour sauvegarder l'Ã©tat du flux (offsets).
* **Chemin** : \`/tmp/checkpoint_customers_...\`
Cela garantit la sÃ©mantique **"Exactly-Once"** (aucun doublon, aucune perte) en cas de redÃ©marrage.

---

## ğŸ§¹ ProcÃ©dure de Reset (DÃ©pannage)

Si vous rencontrez des erreurs de type \`Metadata Log\` ou \`IllegalStateException\` (conflit entre le checkpoint et HDFS), ou si vous souhaitez relancer le traitement depuis le dÃ©but (offset 0), **suivez impÃ©rativement cette procÃ©dure de nettoyage** :

**1. ArrÃªter le Producer et le Job Spark (Ctrl+C).**

**2. Supprimer les mÃ©tadonnÃ©es locales (Le Cerveau) :**
\`\`\`bash
rm -rf /tmp/checkpoint_customers_usa_v2
rm -rf /tmp/checkpoint_customers_alerts_v2
\`\`\`

**3. Supprimer les donnÃ©es sur HDFS (La Destination) :**
\`\`\`bash
hdfs dfs -rm -r /user/maria_dev/customers_usa_v2
hdfs dfs -rm -r /user/maria_dev/customers_alerts_v2
\`\`\`

**4. Relancer le Producer puis le Job Spark.**

---

## ğŸ“Š VÃ©rification des RÃ©sultats

Pour vÃ©rifier que les donnÃ©es arrivent bien sur HDFS :

\`\`\`bash
# Lister les fichiers
hdfs dfs -ls /user/maria_dev/customers_usa_v2

# Lire le contenu d'un fichier (exemple)
hdfs dfs -cat /user/maria_dev/customers_usa_v2/part-00000-....json
\`\`\`
